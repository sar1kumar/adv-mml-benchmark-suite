models:
  gemma:
    type: "ollama"
    model_name: "gemma3:27b"
    max_tokens: 128000  # 128k max tokens context window
    temperature: 1
    top_k: 64
    top_p: 0.95
    
  gemini:
    type: "api"
    model_name: "gemini-2.0-flash"
    api_key: "${GEMINI_API_KEY}"
    max_tokens: 128000
    temperature: 1
    top_k: 64
    top_p: 0.95

tasks:
  sme:
    type: "sme"
    data_path: "data/sme/images"
    split: ["test"]
    sample_size: 10
    prompt_config:
      num_prompts: 8
      method: "random"
    random_seed: 42
    metrics: ["accuracy", "f1"]
    
  vqa_rad:
    type: "vqa_rad"
    data_path: "data/vqa_rad"
    split: ["test"]
    sample_size: 10
    random_seed: 42
    metrics: ["accuracy"]
    
  embodied_vqa:
    type: "embodied_vqa"
    data_path: "data/embodied_vqa"
    split: ["train", "val"]
    metrics: ["accuracy", "rouge"]

logging:
  wandb:
    project: "multimodal-benchmarks"
    entity: "${WANDB_ENTITY}"
    enabled: True
    run_name: "multi-scenario-benchmark"
  save_predictions: true
  output_dir: "results"

device: "cuda"
batch_size: 8
num_workers: 4