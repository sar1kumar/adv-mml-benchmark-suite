models:
  gemma3:27b:
    type: "ollama"
    model_name: "gemma3:27b"
    max_tokens: 128000 # 128k max tokens context window
    temperature: 1
    top_k: 64
    top_p: 0.95

tasks:
  sme:
    type: "sme"
    data_path: "data/sme/images"
    split: ["test"]
    sample_size: 10
    prompt_config:
      num_prompts: 8
      method: "random"
    random_seed: 42

logging:
  wandb:
    project: "multimodal-benchmarks"
    entity: "sme"
    enabled: True
    run_name: "test-run-log"
  save_predictions: True
  output_dir: "results"

device: "cuda"
batch_size: 8
num_workers: 4